{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddd9d611-859a-482c-86d9-2197068e281e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Archivo articles.json eliminado exitosamente.\n",
       "Noticias guardadas exitosamente en Azure Blob Storage. Total de noticias guardadas: 2100\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Archivo articles.json eliminado exitosamente.\nNoticias guardadas exitosamente en Azure Blob Storage. Total de noticias guardadas: 2100\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Configura las variables de conexión\n",
    "jdbcHostname = \"**********\"\n",
    "jdbcPort = ****  # Puerto por defecto de SQL Server\n",
    "jdbcDatabase = \"****\"\n",
    "jdbcUsername = \"*******\"\n",
    "jdbcPassword = \"*******\"\n",
    "\n",
    "# Construye la URL JDBC\n",
    "jdbcUrl = f\"jdbc:sqlserver://{jdbcHostname}:{jdbcPort};databaseName={jdbcDatabase}\"\n",
    "\n",
    "# Opciones de conexión\n",
    "connectionProperties = {\n",
    "    \"user\": jdbcUsername,\n",
    "    \"password\": jdbcPassword,\n",
    "    \"driver\": \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"\n",
    "}\n",
    "\n",
    "# Consulta SQL\n",
    "query = \"\"\"\n",
    "SELECT [contentId]\n",
    "      ,[absoluteURL]\n",
    "      ,[topicName]\n",
    "FROM [dbo].[ARA_DIM_ARTICLES]\n",
    "WHERE CAST([publishedDate] AS DATE) BETWEEN '2023-05-01' AND '2024-05-31' \n",
    "  AND siteId=4 \n",
    "  AND topicName IS NOT NULL\n",
    "  AND contentType NOT IN ('breu', 'video', 'videoembed', 'poll', 'external', 'publication', 'live', 'cartoon', 'photogallery', 'story', 'discussion','podcast')\n",
    "  AND isBrandedContent='false'\n",
    "  AND bodyCharacters<8000\n",
    "  AND [topicName] IN ('Guerra entre Israel i Palestina', 'Eleccions al Parlament', 'L''atac rus a Ucraïna', 'Eleccions municipals', 'Negociacions per a la investidura a l''Estat',\n",
    "                      'La gran sequera', 'El nou govern de Pedro Sánchez', 'El petó forçat de Luis Rubiales', 'Informe PISA')\n",
    "\"\"\"\n",
    "\n",
    "# Leer datos desde SQL Server usando la consulta\n",
    "df = spark.read.jdbc(url=jdbcUrl, table=f\"({query}) AS ARA_DIM_ARTICLES\", properties=connectionProperties)\n",
    "\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
    "import json\n",
    "from newspaper import Article\n",
    "import re\n",
    "import time\n",
    "\n",
    "# Configurar la conexión con Azure Blob Storage\n",
    "connection_string = \"DefaultEndpointsProtocol=https;AccountName=aramlstoragetest;AccountKey=aDjsXo8+Zyd3DdpVLeBwsiOCYAw9kUiXSiPE0/vv+AuR7LinCtriH+xMQB8YTaQZK7WTIqLxNRvY+ASt1x1lBw==;EndpointSuffix=core.windows.net\"\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "container_name = \"newsdata\"\n",
    "blob_name = \"articles.json\"\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "# Eliminar el archivo existente si existe\n",
    "try:\n",
    "    blob_client = container_client.get_blob_client(blob_name)\n",
    "    blob_client.delete_blob()\n",
    "    print(f\"Archivo {blob_name} eliminado exitosamente.\")\n",
    "except Exception as e:\n",
    "    if \"BlobNotFound\" in str(e):\n",
    "        print(f\"El archivo {blob_name} no existe. Continuando con el proceso...\")\n",
    "    else:\n",
    "        print(f\"No se pudo eliminar el archivo {blob_name}: {e}\")\n",
    "\n",
    "# Función para limpiar el texto\n",
    "def preprocess_text(text):\n",
    "    # Reemplazar múltiples espacios por un solo espacio\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Insertar espacio después de palabras concatenadas sin espacio\n",
    "    text = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', text)\n",
    "    # Eliminar frases que comienzan con \"Inscriu-te\" y terminan con \"Inscriu-t’hi\"\n",
    "    text = re.sub(r'Inscriu-te.*?Inscriu-t’hi', '', text)\n",
    "    return text\n",
    "\n",
    "# Función para descargar el contenido de una URL con reintentos\n",
    "def download_article(url, retries=5, backoff_factor=0.3):\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            article = Article(url)\n",
    "            article.download()\n",
    "            article.parse()\n",
    "            cleaned_text = preprocess_text(article.text)\n",
    "            return {\n",
    "                'url': url,\n",
    "                'text': cleaned_text\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error descargando {url}: {e}\")\n",
    "            if i < retries - 1:  # No esperar después del último intento\n",
    "                wait_time = backoff_factor * (2 ** i)  # Espera exponencial\n",
    "                print(f\"Reintentando en {wait_time} segundos...\")\n",
    "                time.sleep(wait_time)\n",
    "    return None  # Retorna None si todos los intentos fallan\n",
    "\n",
    "# Descargar las noticias y preprocesar el texto\n",
    "articles_data = []\n",
    "urls = df.select(\"absoluteURL\", \"contentId\", \"topicName\").collect()\n",
    "\n",
    "for row in urls:\n",
    "    url = row['absoluteURL']\n",
    "    content_id = row['contentId']\n",
    "    topic_name = row['topicName']\n",
    "    article = download_article(url)\n",
    "    if article:\n",
    "        article['contentId'] = content_id\n",
    "        article['topicName'] = topic_name\n",
    "        articles_data.append(article)\n",
    "\n",
    "# Convertir a JSON\n",
    "articles_json = json.dumps(articles_data, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Crear BlobClient\n",
    "blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
    "\n",
    "# Subir el JSON al Blob Storage\n",
    "blob_client.upload_blob(articles_json, blob_type=\"BlockBlob\", overwrite=True)\n",
    "\n",
    "# Mensaje final con el número de noticias guardadas\n",
    "print(f\"Noticias guardadas exitosamente en Azure Blob Storage. Total de noticias guardadas: {len(articles_data)}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "BO Recolección noticias y limpieza de datos",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
