{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53ad3909-0cec-46fc-8b59-98e48630fda7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">   clusterid contentId\n",
       "0          5   4685429\n",
       "1          2   4724753\n",
       "2          4   4768899\n",
       "3          3   4866215\n",
       "4          2   4866297\n",
       "Datos insertados en la tabla cluster_umap_hdbscan_sbert_cls_topics_normalized en la base de datos.\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">   clusterid contentId\n0          5   4685429\n1          2   4724753\n2          4   4768899\n3          3   4866215\n4          2   4866297\nDatos insertados en la tabla cluster_umap_hdbscan_sbert_cls_topics_normalized en la base de datos.\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "import json\n",
    "\n",
    "# Conexión a Azure Blob Storage y descarga del archivo JSON\n",
    "connection_string = \"*************************************\"\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "container_name = \"********\"\n",
    "blob_name = \"cluster_umap_hdbscan_sbert_cls_topics_normalized.json\"\n",
    "\n",
    "blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
    "downloaded_blob = blob_client.download_blob().readall()\n",
    "articles_data = json.loads(downloaded_blob)\n",
    "\n",
    "extracted_data = [{\"clusterid\": item[\"idCluster\"], \"contentId\": item[\"contentId\"]} for item in articles_data]\n",
    "df = pd.DataFrame(extracted_data)\n",
    "\n",
    "if not df.empty:\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"El archivo JSON está vacío.\")\n",
    "\n",
    "# Crear una sesión de Spark\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark_df = spark.createDataFrame(df)\n",
    "\n",
    "# Parámetros de conexión JDBC\n",
    "jdbcHostname = \"*********************\"\n",
    "jdbcPort = 1****\n",
    "jdbcDatabase = \"*******\"\n",
    "jdbcUsername = \"*******\"\n",
    "jdbcPassword = \"*******\"\n",
    "jdbcUrl = f\"jdbc:sqlserver://{jdbcHostname}:{jdbcPort};databaseName={jdbcDatabase}\"\n",
    "\n",
    "connectionProperties = {\n",
    "    \"user\": jdbcUsername,\n",
    "    \"password\": jdbcPassword,\n",
    "    \"driver\": \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"\n",
    "}\n",
    "\n",
    "# Define the table name\n",
    "table_name = \"cluster_umap_hdbscan_sbert_cls_topics_normalized\"\n",
    "\n",
    "# Escribir los datos en la tabla SQL utilizando JDBC\n",
    "spark_df.write.jdbc(url=jdbcUrl, table=table_name, mode='append', properties=connectionProperties)\n",
    "\n",
    "print(f\"Datos insertados en la tabla {table_name} en la base de datos.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "15 - Envío clústeres a Producción",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
